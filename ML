# Load Required Libraries
library(dplyr)
library(lubridate)
library(tidyverse)
library(vader)
library(prophet)
library(xgboost)
library(caret)
library(keras)
library(tensorflow)
library(zoo)
library(Metrics)  # For RMSE calculation

# Load dataset
df <- read.csv("jj_complaints.csv", stringsAsFactors = FALSE)

# Convert 'Date' to Date type
df$Date <- mdy_hm(df$Date)  # Adjusts for "12/30/2024 25:5" format

# Aggregate complaints by month
df$YearMonth <- floor_date(df$Date, "month")

monthly_complaints <- df %>%
  group_by(YearMonth) %>%
  summarise(Complaint_Volume = n(), .groups = 'drop')

# Apply Sentiment Analysis using VADER
df$Sentiment_Score <- vader_df(df$Complaint_Text)$compound
monthly_sentiment <- df %>%
  group_by(YearMonth) %>%
  summarise(Sentiment_Score = mean(Sentiment_Score, na.rm = TRUE), .groups = 'drop')

# Merge complaints and sentiment data
data <- monthly_complaints %>%
  left_join(monthly_sentiment, by = "YearMonth")

# Fill missing values with 0
data[is.na(data)] <- 0

# Create lag features (last 3 months of complaint volume)
data <- data %>%
  arrange(YearMonth) %>%
  mutate(Lag_1 = lag(Complaint_Volume, 1),
         Lag_2 = lag(Complaint_Volume, 2),
         Lag_3 = lag(Complaint_Volume, 3))

# Rolling Averages
data <- data %>%
  mutate(Rolling_3 = zoo::rollmean(Complaint_Volume, 3, fill = NA, align = "right"),
         Rolling_6 = zoo::rollmean(Complaint_Volume, 6, fill = NA, align = "right"))

# Drop initial rows with NA due to lag/rolling calculations
data <- na.omit(data)

# Split into train and test (80% train, 20% test)
split_idx <- round(nrow(data) * 0.8)
train <- data[1:split_idx, ]
test <- data[(split_idx + 1):nrow(data), ]

### ----- 1. Prophet Model -----
prophet_data <- train %>%
  select(ds = YearMonth, y = Complaint_Volume)

prophet_model <- prophet()
prophet_model <- add_regressor(prophet_model, "Sentiment_Score")
prophet_model <- fit.prophet(prophet_model, prophet_data)

future <- make_future_dataframe(prophet_model, periods = nrow(test), freq = "month")
future$Sentiment_Score <- test$Sentiment_Score
prophet_forecast <- predict(prophet_model, future)
prophet_pred <- tail(prophet_forecast$yhat, nrow(test))

# Calculate RMSE for Prophet
prophet_rmse <- rmse(test$Complaint_Volume, prophet_pred)

### ----- 2. XGBoost Model -----
xgb_train <- train %>% select(-YearMonth)
xgb_test <- test %>% select(-YearMonth)

xgb_model <- xgboost(
  data = as.matrix(xgb_train %>% select(-Complaint_Volume)),
  label = xgb_train$Complaint_Volume,
  nrounds = 100,
  objective = "reg:squarederror",
  verbose = 0
)

xgb_pred <- predict(xgb_model, as.matrix(xgb_test %>% select(-Complaint_Volume)))

# Calculate RMSE for XGBoost
xgb_rmse <- rmse(test$Complaint_Volume, xgb_pred)

### ----- 3. LSTM Model -----
# Normalize data
normalize <- function(x) {(x - min(x)) / (max(x) - min(x))}
train_norm <- as.data.frame(lapply(train[-1], normalize))
test_norm <- as.data.frame(lapply(test[-1], normalize))

# Convert to array for LSTM
train_x <- array(train_norm %>% select(-Complaint_Volume), dim = c(nrow(train_norm), ncol(train_norm), 1))
train_y <- train_norm$Complaint_Volume
test_x <- array(test_norm %>% select(-Complaint_Volume), dim = c(nrow(test_norm), ncol(test_norm), 1))

# Build LSTM Model
lstm_model <- keras_model_sequential() %>%
  layer_lstm(units = 50, input_shape = c(ncol(train_norm), 1)) %>%
  layer_dense(units = 1)

lstm_model %>% compile(loss = "mse", optimizer = "adam")

# Train LSTM
lstm_model %>% fit(train_x, train_y, epochs = 50, batch_size = 1, verbose = 0)

# Make predictions
lstm_pred <- lstm_model %>% predict(test_x)

# Convert back to original scale
lstm_pred <- lstm_pred * (max(train$Complaint_Volume) - min(train$Complaint_Volume)) + min(train$Complaint_Volume)

# Calculate RMSE for LSTM
lstm_rmse <- rmse(test$Complaint_Volume, lstm_pred)

### ----- Model Selection -----
rmse_results <- data.frame(
  Model = c("Prophet", "XGBoost", "LSTM"),
  RMSE = c(prophet_rmse, xgb_rmse, lstm_rmse)
)

best_model <- rmse_results %>% filter(RMSE == min(RMSE))

# Print RMSE Results
print(rmse_results)
cat("\nBest Model:", best_model$Model, "with RMSE:", best_model$RMSE, "\n")
