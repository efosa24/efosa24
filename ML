# Load Required Libraries
library(dplyr)
library(lubridate)
library(tidyverse)
library(prophet)
library(xgboost)
library(caret)
library(keras)
library(tensorflow)
library(zoo)
library(ggplot2)
library(Metrics)  # For RMSE calculation

# Load dataset
df <- read.csv("jj_complaints.csv", stringsAsFactors = FALSE)

# Convert 'Date' to Date type
df$Date <- mdy_hm(df$Date)  # Adjust for format like "12/30/2024 25:5"

# Aggregate complaints by month
df$YearMonth <- floor_date(df$Date, "month")

monthly_complaints <- df %>%
  group_by(YearMonth) %>%
  summarise(Complaint_Volume = n(), .groups = 'drop')

# Fill missing values with 0
data <- monthly_complaints
data[is.na(data)] <- 0

# Create lag features (last 3 months of complaint volume)
data <- data %>%
  arrange(YearMonth) %>%
  mutate(Lag_1 = lag(Complaint_Volume, 1),
         Lag_2 = lag(Complaint_Volume, 2),
         Lag_3 = lag(Complaint_Volume, 3))

# Rolling Averages
data <- data %>%
  mutate(Rolling_3 = zoo::rollmean(Complaint_Volume, 3, fill = NA, align = "right"),
         Rolling_6 = zoo::rollmean(Complaint_Volume, 6, fill = NA, align = "right"))

# Drop first few rows with NaN due to lag features
data <- na.omit(data)

# ðŸ“Œ Train-Test Split
train_size <- floor(0.8 * nrow(data))
train <- data[1:train_size, ]
test <- data[(train_size + 1):nrow(data), ]

# ---------------------------------------------------------------
# âœ… PROPHET MODEL
# ---------------------------------------------------------------
prophet_data <- data %>%
  select(YearMonth, Complaint_Volume) %>%
  rename(ds = YearMonth, y = Complaint_Volume)

m <- prophet(prophet_data)
future <- make_future_dataframe(m, periods = 12, freq = "month")  # Predict 12 months ahead
forecast <- predict(m, future)

# ðŸ“Œ Plot Prophet Predictions
ggplot() +
  geom_line(data = prophet_data, aes(x = ds, y = y), color = "blue") +
  geom_line(data = forecast, aes(x = ds, y = yhat), color = "red") +
  labs(title = "Prophet Forecast vs Actual", x = "Date", y = "Complaint Volume")

# ---------------------------------------------------------------
# âœ… XGBOOST MODEL
# ---------------------------------------------------------------
x_train <- as.matrix(train %>% select(-YearMonth, -Complaint_Volume))
y_train <- train$Complaint_Volume

x_test <- as.matrix(test %>% select(-YearMonth, -Complaint_Volume))
y_test <- test$Complaint_Volume

xgb_model <- xgboost(data = x_train, label = y_train, nrounds = 100, objective = "reg:squarederror", verbose = 0)

# Predict using XGBoost
xgb_pred <- predict(xgb_model, x_test)

# ðŸ“Œ Plot XGBoost Predictions
ggplot() +
  geom_line(data = test, aes(x = YearMonth, y = Complaint_Volume), color = "blue") +
  geom_line(data = test, aes(x = YearMonth, y = xgb_pred), color = "red") +
  labs(title = "XGBoost Forecast vs Actual", x = "Date", y = "Complaint Volume")

# ---------------------------------------------------------------
# âœ… LSTM MODEL
# ---------------------------------------------------------------
# Normalize Data
scaler <- preProcess(train %>% select(-YearMonth), method = "range")
train_scaled <- predict(scaler, train %>% select(-YearMonth))
test_scaled <- predict(scaler, test %>% select(-YearMonth))

# Reshape Data for LSTM (3D Tensor)
X_train <- array(train_scaled[, -1], dim = c(nrow(train_scaled), ncol(train_scaled) - 1, 1))
y_train <- train_scaled[, 1]

X_test <- array(test_scaled[, -1], dim = c(nrow(test_scaled), ncol(test_scaled) - 1, 1))
y_test <- test_scaled[, 1]

# Define LSTM Model
model <- keras_model_sequential() %>%
  layer_lstm(units = 50, return_sequences = TRUE, input_shape = c(dim(X_train)[2], 1)) %>%
  layer_lstm(units = 50) %>%
  layer_dense(units = 1)

# Compile and Train Model
model %>% compile(loss = 'mean_squared_error', optimizer = 'adam')
model %>% fit(X_train, y_train, epochs = 50, batch_size = 1, verbose = 0)

# Predict using LSTM
lstm_pred <- model %>% predict(X_test)
lstm_pred <- predict(scaler, data.frame(Complaint_Volume = lstm_pred))  # Inverse scaling

# ðŸ“Œ Plot LSTM Predictions
ggplot() +
  geom_line(data = test, aes(x = YearMonth, y = Complaint_Volume), color = "blue") +
  geom_line(data = test, aes(x = YearMonth, y = lstm_pred[,1]), color = "red") +
  labs(title = "LSTM Forecast vs Actual", x = "Date", y = "Complaint Volume")

# ---------------------------------------------------------------
# âœ… Model Selection (Compare RMSE)
# ---------------------------------------------------------------
prophet_rmse <- rmse(test$Complaint_Volume, forecast$yhat[train_size + 1:nrow(test)])
xgb_rmse <- rmse(test$Complaint_Volume, xgb_pred)
lstm_rmse <- rmse(test$Complaint_Volume, lstm_pred[,1])

rmse_values <- data.frame(
  Model = c("Prophet", "XGBoost", "LSTM"),
  RMSE = c(prophet_rmse, xgb_rmse, lstm_rmse)
)

print(rmse_values)

# Select Best Model
best_model <- rmse_values[which.min(rmse_values$RMSE), "Model"]
cat("Best model based on RMSE:", best_model)
