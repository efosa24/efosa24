import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
import xgboost as xgb
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

# Load dataset
df = pd.read_csv("jj_complaints.csv")

# Convert 'Date' to datetime
df['Date'] = pd.to_datetime(df['Date'])

# Aggregate complaints by month
df['YearMonth'] = df['Date'].dt.to_period('M')
monthly_complaints = df.groupby('YearMonth').size().reset_index(name='Complaint_Volume')
monthly_complaints['YearMonth'] = monthly_complaints['YearMonth'].astype(str)
monthly_complaints['YearMonth'] = pd.to_datetime(monthly_complaints['YearMonth'])

# Apply Sentiment Analysis
analyzer = SentimentIntensityAnalyzer()
df['Sentiment_Score'] = df['Complaint_Text'].apply(lambda x: analyzer.polarity_scores(str(x))['compound'])
monthly_sentiment = df.groupby('YearMonth')['Sentiment_Score'].mean().reset_index()

# Aggregate marketing spend by month
monthly_marketing = df.groupby('YearMonth')['Marketing_Spend'].sum().reset_index()

# Merge Data
data = monthly_complaints.merge(monthly_sentiment, on='YearMonth').merge(monthly_marketing, on='YearMonth')

# Create Lag Features
for lag in [1, 2, 3]:
    data[f'Lag_{lag}'] = data['Complaint_Volume'].shift(lag)

# Rolling Averages
data['Rolling_3M'] = data['Complaint_Volume'].rolling(window=3).mean()
data['Rolling_6M'] = data['Complaint_Volume'].rolling(window=6).mean()

# Drop NaN values caused by shifting
data = data.dropna()

# Normalize Data
scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data.drop(columns=['YearMonth']))

# Split into Train & Test
train_size = int(len(data) * 0.8)
train, test = data_scaled[:train_size], data_scaled[train_size:]

X_train, y_train = train[:, 1:], train[:, 0]  # Features & Target
X_test, y_test = test[:, 1:], test[:, 0]

# -------------------- XGBoost Model --------------------
xgb_model = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, objective='reg:squarederror')
xgb_model.fit(X_train, y_train)

# Predict with XGBoost
xgb_preds = xgb_model.predict(X_test)

# -------------------- LSTM Model --------------------
X_train_lstm, X_test_lstm = X_train.reshape((-1, X_train.shape[1], 1)), X_test.reshape((-1, X_test.shape[1], 1))

lstm_model = Sequential([
    LSTM(50, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], 1)),
    Dropout(0.2),
    LSTM(50, activation='relu'),
    Dropout(0.2),
    Dense(1)
])

lstm_model.compile(optimizer='adam', loss='mse')
lstm_model.fit(X_train_lstm, y_train, epochs=50, batch_size=8, verbose=1)

# Predict with LSTM
lstm_preds = lstm_model.predict(X_test_lstm)

# -------------------- Compare Results --------------------
plt.figure(figsize=(12, 5))
plt.plot(data['YearMonth'][train_size:], y_test, label='Actual Complaints', color='black')
plt.plot(data['YearMonth'][train_size:], xgb_preds, label='XGBoost Prediction', color='blue')
plt.plot(data['YearMonth'][train_size:], lstm_preds, label='LSTM Prediction', color='red')
plt.legend()
plt.title('Complaint Volume Prediction')
plt.show()
